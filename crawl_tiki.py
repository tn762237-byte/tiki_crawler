pip install requests
import requests
import time
import csv
import random
from datetime import datetime

# --- C·∫§U H√åNH ---
# 1. User-Agent (Gi·∫£ l·∫≠p tr√¨nh duy·ªát th·∫≠t ƒë·ªÉ tr√°nh b·ªã ch·∫∑n)
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Referer': 'https://tiki.vn/',
    'Accept': 'application/json'
}

# 2. Ng√†y c·∫ßn l·∫•y d·ªØ li·ªáu (NƒÉm-Th√°ng-Ng√†y)
# L∆ØU √ù: H√£y ƒë·ªïi th√†nh ng√†y g·∫ßn nh·∫•t ƒë·ªÉ test (v√≠ d·ª• ng√†y h√¥m qua) v√¨ 5/9/2025 ch∆∞a ƒë·∫øn.
TARGET_DATE_STR = "2025-09-05" 
CATEGORY_ID = 8322 # Nh√† s√°ch Tiki

# Chuy·ªÉn ƒë·ªïi ng√†y m·ª•c ti√™u
target_date = datetime.strptime(TARGET_DATE_STR, "%Y-%m-%d").date()

def get_product_date(product_id):
    """
    H√†m g·ªçi API chi ti·∫øt ƒë·ªÉ l·∫•y ng√†y t·∫°o s·∫£n ph·∫©m
    V√¨ API Listing th∆∞·ªùng kh√¥ng c√≥ ng√†y ch√≠nh x√°c.
    """
    url = f"https://tiki.vn/api/v2/products/{product_id}"
    try:
        # Sleep ng·∫´u nhi√™n ƒë·ªÉ kh√¥ng b·ªã ch·∫∑n khi g·ªçi li√™n t·ª•c
        time.sleep(random.uniform(0.5, 1.5)) 
        
        response = requests.get(url, headers=HEADERS, timeout=5)
        if response.status_code == 200:
            data = response.json()
            # Tiki d√πng inventory_type ho·∫∑c created_at
            # ∆Øu ti√™n l·∫•y created_at (ng√†y t·∫°o) ho·∫∑c updated_at (ng√†y c·∫≠p nh·∫≠t)
            timestamp = data.get('created_at')
            if timestamp:
                return datetime.fromtimestamp(timestamp).date()
    except Exception:
        pass
    return None

def crawl_data():
    page = 1
    results = []
    stop_crawling = False

    print(f"üöÄ B·∫Øt ƒë·∫ßu crawl d·ªØ li·ªáu ng√†y: {target_date}")

    while not stop_crawling:
        # sort=newest ƒë·ªÉ ƒë·∫£m b·∫£o l·∫•y h√†ng m·ªõi nh·∫•t tr∆∞·ªõc
        url = f"https://tiki.vn/api/v2/listings?limit=40&include=advertisement&category={CATEGORY_ID}&page={page}&sort=newest"
        
        try:
            print(f"--> ƒêang t·∫£i danh s√°ch trang {page}...")
            response = requests.get(url, headers=HEADERS, timeout=10)
            
            if response.status_code != 200:
                print(f"‚ùå L·ªói API Listing: {response.status_code}")
                break

            data = response.json()
            items = data.get('data', [])

            if not items:
                print("‚ö†Ô∏è H·∫øt s·∫£n ph·∫©m. D·ª´ng.")
                break

            for item in items:
                p_id = item.get('id')
                p_name = item.get('name')
                p_price = item.get('price')

                # G·ªçi h√†m l·∫•y ng√†y chi ti·∫øt (Quan tr·ªçng)
                p_date = get_product_date(p_id)

                if p_date:
                    print(f"   Checking: {p_name[:30]}... | Ng√†y: {p_date}")
                    
                    if p_date == target_date:
                        # 1. ƒê√∫ng ng√†y -> L∆∞u
                        results.append({
                            'id': p_id,
                            'name': p_name,
                            'price': p_price,
                            'date': str(p_date),
                            'url': f"https://tiki.vn/{item.get('url_path')}"
                        })
                        print("   ‚úÖ ƒê√É L·∫§Y!")

                    elif p_date < target_date:
                        # 2. G·∫∑p ng√†y c≈© h∆°n -> D·ª´ng tool
                        print(f"üõë ƒê√£ g·∫∑p ng√†y c≈© h∆°n ({p_date}). D·ª´ng to√†n b·ªô.")
                        stop_crawling = True
                        break
                    
                    # 3. N·∫øu p_date > target_date (ng√†y t∆∞∆°ng lai/m·ªõi h∆°n) -> Ti·∫øp t·ª•c
                else:
                    print(f"   ‚ö†Ô∏è Kh√¥ng l·∫•y ƒë∆∞·ª£c ng√†y c·ªßa ID {p_id}")

            page += 1
            time.sleep(1) # Ngh·ªâ gi·ªØa c√°c trang

        except Exception as e:
            print(f"‚ùå L·ªói h·ªá th·ªëng: {e}")
            break
            
    return results

if __name__ == "__main__":
    data = crawl_data()
    
    # L∆∞u file CSV
    filename = "ket_qua_tiki.csv"
    if data:
        keys = data[0].keys()
        with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=keys)
            writer.writeheader()
            writer.writerows(data)
        print(f"\nüéâ Ho√†n t·∫•t! ƒê√£ l∆∞u {len(data)} d√≤ng v√†o {filename}")
    else:
        # T·∫°o file r·ªóng ho·∫∑c ghi log n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ Github kh√¥ng b√°o l·ªói file thi·∫øu
        with open(filename, 'w') as f:
            f.write("Khong co du lieu trung khop")
        print("\n‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu n√†o kh·ªõp ng√†y y√™u c·∫ßu.")
